{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "SgEWJdq02r0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import time"
      ],
      "metadata": {
        "id": "E1wGSBYKQqlO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get API"
      ],
      "metadata": {
        "id": "shCIej8WQm-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SERPAPI_KEY = '3e33047b5d45eba0a802a51a9deed3080ae17717eb542cd3bad23ff48126a1cb'"
      ],
      "metadata": {
        "id": "MbG2SyTNQ41m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Search Function"
      ],
      "metadata": {
        "id": "HKgPO8kyQ-CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_serp_results(query):\n",
        "    search_url = f'https://serpapi.com/search?q={query}&api_key={SERPAPI_KEY}'\n",
        "    response = requests.get(search_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "def extract_email(text):\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "    text = text.replace(\"[at]\", \"@\").replace(\"[dot]\", \".\")\n",
        "\n",
        "    email_regex = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
        "    emails = re.findall(email_regex, text)\n",
        "\n",
        "    return emails if emails else \"N/A\"\n",
        "\n",
        "def extract_creation_date(soup):\n",
        "    # Meta tag - published time\n",
        "    meta_date = soup.find('meta', {'property': 'article:published_time'})\n",
        "    if meta_date and meta_date.get('content'):\n",
        "        return meta_date['content']\n",
        "\n",
        "    # Meta tag - name=\"date\"\n",
        "    meta_date = soup.find('meta', {'name': 'date'})\n",
        "    if meta_date and meta_date.get('content'):\n",
        "        return meta_date['content']\n",
        "\n",
        "    # Tag time\n",
        "    time_tag = soup.find('time')\n",
        "    if time_tag and time_tag.get('datetime'):\n",
        "        return time_tag['datetime']\n",
        "    elif time_tag:\n",
        "        return time_tag.get_text()\n",
        "\n",
        "    # Regex pada teks halaman\n",
        "    # Regex on page text\n",
        "    text = soup.get_text(separator=' ')\n",
        "    date_patterns = [\n",
        "        r'\\b\\d{4}-\\d{2}-\\d{2}\\b',                # 2024-04-08\n",
        "        r'\\b\\d{2}/\\d{2}/\\d{4}\\b',                # 08/04/2024\n",
        "        r'\\b\\d{1,2} \\w+ \\d{4}\\b',                # 8 April 2024\n",
        "    ]\n",
        "    for pattern in date_patterns:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            return match.group()\n",
        "\n",
        "    return \"N/A\""
      ],
      "metadata": {
        "id": "JU8g7jdMQ9k8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_company_info(query):\n",
        "    results = get_serp_results(query)\n",
        "\n",
        "    if results and 'organic_results' in results:\n",
        "        company_info = []\n",
        "\n",
        "        for result in results['organic_results']:\n",
        "            company_name = result.get('title', 'N/A')\n",
        "            company_url = result.get('link', 'N/A')\n",
        "\n",
        "            try:\n",
        "                response = requests.get(company_url, timeout=10)\n",
        "                if response.status_code == 200:\n",
        "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "                    page_emails = extract_email(soup.get_text())\n",
        "                    all_links = find_all_links(soup)\n",
        "                    creation_date = extract_creation_date(soup)\n",
        "                else:\n",
        "                    page_emails = [\"N/A\"]\n",
        "                    all_links = [\"N/A\"]\n",
        "                    creation_date = \"N/A\"\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Error fetching {company_url}: {e}\")\n",
        "                page_emails = [\"N/A\"]\n",
        "                all_links = [\"N/A\"]\n",
        "                creation_date = \"N/A\"\n",
        "\n",
        "            company_info.append({\n",
        "                'company_name': company_name,\n",
        "                'company_url': company_url,\n",
        "                'informal_emails': page_emails,\n",
        "                'links': all_links,\n",
        "                'creation_date': creation_date\n",
        "            })\n",
        "\n",
        "            time.sleep(2)\n",
        "            # Delay untuk jaga-jaga anti blocking\n",
        "            # Delay to prevent blocking\n",
        "\n",
        "        return company_info\n",
        "    else:\n",
        "        print(\"No results found.\")\n",
        "        return []\n",
        "\n",
        "# Contoh Penggunaan\n",
        "# Example of use\n",
        "query = \"Saas Agency\"\n",
        "company_data = extract_company_info(query)\n",
        "\n",
        "# Result\n",
        "for company in company_data:\n",
        "    print(\"\\nCompany Name:\", company['company_name'])\n",
        "    print(\"Company URL:\", company['company_url'])\n",
        "    print(\"Emails:\", company['informal_emails'])\n",
        "    print(\"Links:\", company['links'][:5])  # Print 5 link pertama\n",
        "    print(\"Creation Date:\", company['creation_date'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEFcnOJORPrn",
        "outputId": "ec11bb06-3db2-479c-c2af-fc214a4445e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company Name: B2B SaaS Marketing Agency | SaaS Growth | Kalungi, Inc.\n",
            "Company URL: https://www.kalungi.com/\n",
            "Emails: ['contact@kalungi.com']\n",
            "Links: ['https://www.kalungi.com', 'https://www.kalungi.com/services/full-service-b2b-saas-marketing-team', 'https://www.kalungi.com/services/audit', 'https://www.kalungi.com/services/saas-cmo', 'https://www.kalungi.com/services/coach']\n",
            "Creation Date: N/A\n",
            "\n",
            "Company Name: SaaS Marketing Agency Driving Predictable Growth\n",
            "Company URL: https://www.simpletiger.com/\n",
            "Emails: N/A\n",
            "Links: ['/', '/saas-seo-agency', '/services/seo', '/services/keyword-research', '/services/technical-seo']\n",
            "Creation Date: 12 months 1200\n",
            "\n",
            "Company Name: Growfusely: SaaS Content Marketing Agency\n",
            "Company URL: https://growfusely.com/\n",
            "Emails: N/A\n",
            "Links: ['https://growfusely.com', 'index.php', 'https://growfusely.com/contact-us/', 'https://growfusely.com/about-us/', 'https://growfusely.com/about-us/']\n",
            "Creation Date: N/A\n",
            "\n",
            "Company Name: Saas, Agency or Job?\n",
            "Company URL: https://www.reddit.com/r/agency/comments/1g4g15q/saas_agency_or_job/\n",
            "Emails: ['N/A']\n",
            "Links: ['N/A']\n",
            "Creation Date: N/A\n",
            "\n",
            "Company Name: Top 5 U.S. SaaS Marketing Agencies in 2025\n",
            "Company URL: https://www.310creative.com/blog/saas-marketing-agencies\n",
            "Emails: N/A\n",
            "Links: ['/', '/', '/', 'https://www.310creative.com/agency', 'https://www.310creative.com/agency/overview']\n",
            "Creation Date: N/A\n",
            "\n",
            "Company Name: TripleDart - SaaS Marketing Agency for 2025 and Beyond\n",
            "Company URL: https://www.tripledart.com/\n",
            "Emails: N/A\n",
            "Links: ['/b2b-saas-marketing/b2b-saas-marketing-guide', 'https://www.tripledart.com/coach/ai-and-seo-adapting-to-the-future-of-search', '/', '/about', '/startups']\n",
            "Creation Date: N/A\n",
            "\n",
            "Company Name: Top 27 B2B SaaS Marketing Agencies in 2025\n",
            "Company URL: https://nogood.io/2024/11/15/b2b-saas-marketing-agencies/\n",
            "Emails: ['N/A']\n",
            "Links: ['N/A']\n",
            "Creation Date: N/A\n",
            "\n",
            "Company Name: SaaS Marketing Agency\n",
            "Company URL: https://www.singlegrain.com/saas-marketing-agency/\n",
            "Emails: ['contact@singlegrain.com']\n",
            "Links: ['#main', 'https://www.singlegrain.com/careers/?utm_source=singlegrain&utm_medium=hello-bar&utm_campaign=careers', 'https://www.singlegrain.com/', 'javascript:;', 'https://www.singlegrain.com/services/seo/']\n",
            "Creation Date: N/A\n",
            "\n",
            "Company Name: 21 Best B2B SaaS Marketing Agencies To Work With in 2025\n",
            "Company URL: https://www.omnius.so/blog/best-saas-marketing-agencies\n",
            "Emails: N/A\n",
            "Links: ['/', '/content-marketing', '/seo', '/web-development', '/programmatic-seo']\n",
            "Creation Date: 2 Apr 2025\n"
          ]
        }
      ]
    }
  ]
}